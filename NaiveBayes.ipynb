{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h2o\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import os,json\n",
    "\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_json = 'bitbootcamp/tablets/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "cols = ['Title', 'Author', 'ReviewID','Overall','Content','Date']\n",
    "jsons_data = pd.DataFrame(columns=cols)\n",
    "\n",
    "#Store where to separate df into csv's\n",
    "length=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer=SnowballStemmer('english')\n",
    "def text_processing(text):\n",
    "    bs_obj = BeautifulSoup(text.lower(),\"lxml\")\n",
    "    new_words=[stemmer.stem(word.encode('ascii','ignore')) for word in bs_obj.get_text().split()]\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 7: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-42cec7d1eb2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                     \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mjsons_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjsons_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-c24216826fe4>\u001b[0m in \u001b[0;36mtext_processing\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbs_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m###Use utf-8 here for converting to csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mnew_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbs_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Robert\\Anaconda2\\lib\\site-packages\\nltk\\stem\\snowball.pyc\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;31m# Map the different apostrophe characters to a single consistent one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m         word = (word.replace(\"\\u2019\", \"\\x27\")\n\u001b[0m\u001b[0;32m    693\u001b[0m                     \u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\u2018\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\x27\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m                     .replace(\"\\u201B\", \"\\x27\"))\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 7: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "#Load first 100 json\n",
    "for index, js in enumerate(json_files[:100]):\n",
    "    with open(os.path.join(path_to_json, js)) as json_file:\n",
    "        json_text = json.load(json_file)\n",
    "        \n",
    "        for item in json_text['Reviews']:\n",
    "            \n",
    "            l = []\n",
    "            for col in cols:\n",
    "                if item[col] is None:\n",
    "                    item[col]=''\n",
    "                l.append(text_processing(item[col]))\n",
    "            jsons_data.loc[len(jsons_data)] = l\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#jsons_data['Content']=jsons_data['Content'].apply(text_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#jsons_data[['ReviewID','Overall','Content']].to_csv('bitbootcamp/jsons_data.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load(start,end):\n",
    "    #Open and load in json files\n",
    "    for index, js in enumerate(json_files[start:end]):\n",
    "        with open(os.path.join(path_to_json, js)) as json_file:\n",
    "            json_text = json.load(json_file)\n",
    "\n",
    "            for item in json_text['Reviews']:\n",
    "\n",
    "                l = []\n",
    "                for col in cols:\n",
    "                    if item[col] is None:\n",
    "                        item[col]=''\n",
    "                    l.append(text_processing(item[col]))\n",
    "                jsons_data.loc[len(jsons_data)] = l\n",
    "    #Don't do this due to size limits on to_csv\n",
    "    #jsons_data[['ReviewID','Overall','Content']].to_csv('bitbootcamp/json_data.csv',sep=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robert\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:198: UserWarning: \"c:\\windows\\system32\\drivers\\etc\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  '\"%s\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "load(100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Just going to manually do this rather than in the loops\n",
    "jsons_data[['ReviewID','Overall','Content']][:40000].to_csv('bitbootcamp/json_data1.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jsons_data[['ReviewID','Overall','Content']][40000:54451].to_csv('bitbootcamp/json_data2.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robert\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:198: UserWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  '\"%s\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "load(200,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jsons_data[['ReviewID','Overall','Content']][54451:length].to_csv('bitbootcamp/json_data3.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length=len(jsons_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load(300,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jsons_data[['ReviewID','Overall','Content']][length:].to_csv('bitbootcamp/json_data4.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length=len(jsons_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load(400,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jsons_data[['ReviewID','Overall','Content']][length:].to_csv('bitbootcamp/json_data5.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length=len(jsons_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robert\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:198: UserWarning: \".......\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  '\"%s\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "load(500,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jsons_data[['ReviewID','Overall','Content']][length:].to_csv('bitbootcamp/json_data6.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length=len(jsons_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load(600,700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jsons_data[['ReviewID','Overall','Content']][length:].to_csv('bitbootcamp/json_data7.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length=len(jsons_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load(700,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jsons_data[['ReviewID','Overall','Content']][length:].to_csv('bitbootcamp/json_data8.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length=len(jsons_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load(800,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jsons_data[['ReviewID','Overall','Content']][length:].to_csv('bitbootcamp/json_data9.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length=len(jsons_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load(900,1049)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jsons_data[['ReviewID','Overall','Content']][length:].to_csv('bitbootcamp/json_data10.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145355"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jsons_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#It seems that I actually accidentally loaded them all before\n",
    "df=pd.read_csv('bitbootcamp/json_data.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '4', '3', '1', '2', 'None', 'none'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Overall'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df[df['Overall']!='none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df['Overall']!='None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Overall']=df['Overall'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save now that the data has been \"cleaned\" (i.e. null overall dropped and overall now int)\n",
    "df.to_csv('bitbootcamp/json_data.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewID</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>R2K730ZJFNNF3B</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8842</th>\n",
       "      <td>R2K730ZJFNNF3B</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8844</th>\n",
       "      <td>R2K730ZJFNNF3B</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>R2K730ZJFNNF3B</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12350</th>\n",
       "      <td>R2K730ZJFNNF3B</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12355</th>\n",
       "      <td>R2K730ZJFNNF3B</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ReviewID  Overall Content\n",
       "1656   R2K730ZJFNNF3B        1     NaN\n",
       "8842   R2K730ZJFNNF3B        1     NaN\n",
       "8844   R2K730ZJFNNF3B        1     NaN\n",
       "10870  R2K730ZJFNNF3B        1     NaN\n",
       "12350  R2K730ZJFNNF3B        1     NaN\n",
       "12355  R2K730ZJFNNF3B        1     NaN"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['ReviewID']=='R2K730ZJFNNF3B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df[df['Content'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finally rid of all nulls\n",
    "df.to_csv('bitbootcamp/json_data.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145296"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df['Overall']!=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label(row):\n",
    "    if row['Overall']==1:\n",
    "        return 'negative'\n",
    "    if row['Overall']==2:\n",
    "        return 'negative'\n",
    "    return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Sentiment']=df.apply(label,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer=CountVectorizer(stop_words='english',max_df=0.95,min_df=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=count_vectorizer.fit_transform(df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols=[col if re.match('^[a-zA-z_][a-zA-Z0-9_.]*',col) is not None else 'a'+col for col in count_vectorizer.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews_df=pd.DataFrame(data=x.toarray(),columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_df=pd.merge(pd.DataFrame(df['Sentiment']),reviews_df,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews_df['Sentiment']=reviews_df['Sentiment'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>33 minutes 32 seconds 411 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.2.0.9</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>H2O_started_from_python</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster total memory: </td>\n",
       "<td>1.76 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>127.0.0.1</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54321</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  --------------------------------------\n",
       "H2O cluster uptime:         33 minutes 32 seconds 411 milliseconds\n",
       "H2O cluster version:        3.2.0.9\n",
       "H2O cluster name:           H2O_started_from_python\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster total memory:   1.76 GB\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster healthy:        True\n",
       "H2O Connection ip:          127.0.0.1\n",
       "H2O Connection port:        54321\n",
       "--------------------------  --------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "Uploaded py0ab54df0-385c-4bce-8d41-af4643949ae5 into cluster with 124,902 rows and 301 cols\n"
     ]
    }
   ],
   "source": [
    "reviews_hex=h2o.H2OFrame(reviews_df.to_dict(orient='list'),destination_frame='reviews.hex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_bayes_constructor(features,response,data_hex,train_ratio=0.7,num_models=5,threshold_list=np.arange(0.,1.,0.05),return_cm=True):\n",
    "    auc_list=[]\n",
    "    accuracy_list=[]\n",
    "    if return_cm:\n",
    "        cm_list=[]\n",
    "        \n",
    "    for nn in range(num_models):\n",
    "        #create test and training\n",
    "        random_idx=reviews_hex[response].runif()\n",
    "        data_hex[random_idx<train_ratio]\n",
    "        train_df = data_hex[random_idx<train_ratio]\n",
    "        test_df = data_hex[random_idx>=train_ratio]\n",
    "        model={'x':features,'y':response,'training_frame':train_df,'validation_frame':test_df}\n",
    "        nb_classifier=h2o.naive_bayes(**model)\n",
    "        \n",
    "        auc_list.append(nb_classifier.auc(valid=True))\n",
    "        \n",
    "        accuracy=nb_classifier.accuracy(valid=True)[0][1]\n",
    "        accuracy_list.append(accuracy)\n",
    "        \n",
    "        if return_cm:\n",
    "            cm_model=[]\n",
    "            for thr in threshold_list:\n",
    "                cm_model.append((thr,nb_classifier.confusion_matrix(thresholds=thr,valid=True).to_list()))\n",
    "            cm_list.append(cm_model)\n",
    "            \n",
    "    avg_acc = sum(accuracy_list)/len(accuracy_list)\n",
    "    avg_auc = sum(auc_list)/len(auc_list)\n",
    "            \n",
    "    dic={}\n",
    "    dic['auc_list'] = auc_list\n",
    "    dic['avg_auc'] = avg_auc\n",
    "    dic['acc_list'] = accuracy_list\n",
    "    dic['avg_acc'] = avg_acc\n",
    "            \n",
    "    if return_cm:\n",
    "        dic['cm_list'] = cm_list\n",
    "                \n",
    "    return dic\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=[x for x in reviews_hex.columns if x!='Sentiment']\n",
    "response='Sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "naivebayes Model Build Progress: [##################################################] 100%\n",
      "Could not find exact threshold 0.0; using closest threshold found 3.29601527773e-06.\n",
      "Could not find exact threshold 0.05; using closest threshold found 0.0485672247382.\n",
      "Could not find exact threshold 0.1; using closest threshold found 0.102498205638.\n",
      "Could not find exact threshold 0.15; using closest threshold found 0.150170434432.\n",
      "Could not find exact threshold 0.2; using closest threshold found 0.201446156178.\n",
      "Could not find exact threshold 0.25; using closest threshold found 0.249678702492.\n",
      "Could not find exact threshold 0.3; using closest threshold found 0.301221456853.\n",
      "Could not find exact threshold 0.35; using closest threshold found 0.349157138249.\n",
      "Could not find exact threshold 0.4; using closest threshold found 0.399839412984.\n",
      "Could not find exact threshold 0.45; using closest threshold found 0.450223752107.\n",
      "Could not find exact threshold 0.5; using closest threshold found 0.500295744837.\n",
      "Could not find exact threshold 0.55; using closest threshold found 0.550566307817.\n",
      "Could not find exact threshold 0.6; using closest threshold found 0.599075837635.\n",
      "Could not find exact threshold 0.65; using closest threshold found 0.650263953199.\n",
      "Could not find exact threshold 0.7; using closest threshold found 0.699563880003.\n",
      "Could not find exact threshold 0.75; using closest threshold found 0.749322262117.\n",
      "Could not find exact threshold 0.8; using closest threshold found 0.799145167756.\n",
      "Could not find exact threshold 0.85; using closest threshold found 0.850066238264.\n",
      "Could not find exact threshold 0.9; using closest threshold found 0.901242407104.\n",
      "Could not find exact threshold 0.95; using closest threshold found 0.949246632878.\n",
      "\n",
      "naivebayes Model Build Progress: [##################################################] 100%\n",
      "Could not find exact threshold 0.0; using closest threshold found 2.0626865685e-06.\n",
      "Could not find exact threshold 0.05; using closest threshold found 0.0506826392281.\n",
      "Could not find exact threshold 0.1; using closest threshold found 0.100840526326.\n",
      "Could not find exact threshold 0.15; using closest threshold found 0.150256488851.\n",
      "Could not find exact threshold 0.2; using closest threshold found 0.198092158176.\n",
      "Could not find exact threshold 0.25; using closest threshold found 0.249266566776.\n",
      "Could not find exact threshold 0.3; using closest threshold found 0.300615434006.\n",
      "Could not find exact threshold 0.35; using closest threshold found 0.349069769326.\n",
      "Could not find exact threshold 0.4; using closest threshold found 0.400121081596.\n",
      "Could not find exact threshold 0.45; using closest threshold found 0.450888375516.\n",
      "Could not find exact threshold 0.5; using closest threshold found 0.501855275483.\n",
      "Could not find exact threshold 0.55; using closest threshold found 0.549653114782.\n",
      "Could not find exact threshold 0.6; using closest threshold found 0.600729981619.\n",
      "Could not find exact threshold 0.65; using closest threshold found 0.648956900264.\n",
      "Could not find exact threshold 0.7; using closest threshold found 0.700572245227.\n",
      "Could not find exact threshold 0.75; using closest threshold found 0.74941837659.\n",
      "Could not find exact threshold 0.8; using closest threshold found 0.799811328762.\n",
      "Could not find exact threshold 0.85; using closest threshold found 0.850946688678.\n",
      "Could not find exact threshold 0.9; using closest threshold found 0.89980775829.\n",
      "Could not find exact threshold 0.95; using closest threshold found 0.948919578281.\n",
      "\n",
      "naivebayes Model Build Progress: [##################################################] 100%\n",
      "Could not find exact threshold 0.0; using closest threshold found 4.75914778061e-06.\n",
      "Could not find exact threshold 0.05; using closest threshold found 0.0501563855316.\n",
      "Could not find exact threshold 0.1; using closest threshold found 0.101094160189.\n",
      "Could not find exact threshold 0.15; using closest threshold found 0.149709736709.\n",
      "Could not find exact threshold 0.2; using closest threshold found 0.199234941276.\n",
      "Could not find exact threshold 0.25; using closest threshold found 0.249484436088.\n",
      "Could not find exact threshold 0.3; using closest threshold found 0.29952644629.\n",
      "Could not find exact threshold 0.35; using closest threshold found 0.3494152989.\n",
      "Could not find exact threshold 0.4; using closest threshold found 0.401729668826.\n",
      "Could not find exact threshold 0.45; using closest threshold found 0.447914371101.\n",
      "Could not find exact threshold 0.5; using closest threshold found 0.500480878522.\n",
      "Could not find exact threshold 0.55; using closest threshold found 0.548487082952.\n",
      "Could not find exact threshold 0.6; using closest threshold found 0.600638563798.\n",
      "Could not find exact threshold 0.65; using closest threshold found 0.648577148616.\n",
      "Could not find exact threshold 0.7; using closest threshold found 0.698953232948.\n",
      "Could not find exact threshold 0.75; using closest threshold found 0.751251631258.\n",
      "Could not find exact threshold 0.8; using closest threshold found 0.800466829083.\n",
      "Could not find exact threshold 0.85; using closest threshold found 0.850148458984.\n",
      "Could not find exact threshold 0.9; using closest threshold found 0.899439056786.\n",
      "Could not find exact threshold 0.95; using closest threshold found 0.949914746998.\n",
      "\n",
      "naivebayes Model Build Progress: [##################################################] 100%\n",
      "Could not find exact threshold 0.0; using closest threshold found 3.24844280487e-06.\n",
      "Could not find exact threshold 0.05; using closest threshold found 0.0505697093574.\n",
      "Could not find exact threshold 0.1; using closest threshold found 0.0994302881826.\n",
      "Could not find exact threshold 0.15; using closest threshold found 0.147862497798.\n",
      "Could not find exact threshold 0.2; using closest threshold found 0.200485695399.\n",
      "Could not find exact threshold 0.25; using closest threshold found 0.247934522198.\n",
      "Could not find exact threshold 0.3; using closest threshold found 0.300125528697.\n",
      "Could not find exact threshold 0.35; using closest threshold found 0.350456315656.\n",
      "Could not find exact threshold 0.4; using closest threshold found 0.401842105439.\n",
      "Could not find exact threshold 0.45; using closest threshold found 0.449659266683.\n",
      "Could not find exact threshold 0.5; using closest threshold found 0.497666087628.\n",
      "Could not find exact threshold 0.55; using closest threshold found 0.550868924861.\n",
      "Could not find exact threshold 0.6; using closest threshold found 0.600451503314.\n",
      "Could not find exact threshold 0.65; using closest threshold found 0.648946977733.\n",
      "Could not find exact threshold 0.7; using closest threshold found 0.69907499206.\n",
      "Could not find exact threshold 0.75; using closest threshold found 0.749096574484.\n",
      "Could not find exact threshold 0.8; using closest threshold found 0.802189662308.\n",
      "Could not find exact threshold 0.85; using closest threshold found 0.849118721023.\n",
      "Could not find exact threshold 0.9; using closest threshold found 0.899723405966.\n",
      "Could not find exact threshold 0.95; using closest threshold found 0.950738953444.\n",
      "\n",
      "naivebayes Model Build Progress: [##################################################] 100%\n",
      "Could not find exact threshold 0.0; using closest threshold found 2.75805447546e-06.\n",
      "Could not find exact threshold 0.05; using closest threshold found 0.0508202216175.\n",
      "Could not find exact threshold 0.1; using closest threshold found 0.0988424785894.\n",
      "Could not find exact threshold 0.15; using closest threshold found 0.149084622562.\n",
      "Could not find exact threshold 0.2; using closest threshold found 0.198928043043.\n",
      "Could not find exact threshold 0.25; using closest threshold found 0.25027920146.\n",
      "Could not find exact threshold 0.3; using closest threshold found 0.300930137214.\n",
      "Could not find exact threshold 0.35; using closest threshold found 0.351384823527.\n",
      "Could not find exact threshold 0.4; using closest threshold found 0.399533315687.\n",
      "Could not find exact threshold 0.45; using closest threshold found 0.4497953797.\n",
      "Could not find exact threshold 0.5; using closest threshold found 0.499672018882.\n",
      "Could not find exact threshold 0.55; using closest threshold found 0.550595779691.\n",
      "Could not find exact threshold 0.6; using closest threshold found 0.600748011341.\n",
      "Could not find exact threshold 0.65; using closest threshold found 0.648768250581.\n",
      "Could not find exact threshold 0.7; using closest threshold found 0.700925062225.\n",
      "Could not find exact threshold 0.75; using closest threshold found 0.748977025233.\n",
      "Could not find exact threshold 0.8; using closest threshold found 0.801306951761.\n",
      "Could not find exact threshold 0.85; using closest threshold found 0.849089702648.\n",
      "Could not find exact threshold 0.9; using closest threshold found 0.900589291527.\n",
      "Could not find exact threshold 0.95; using closest threshold found 0.949041320464.\n"
     ]
    }
   ],
   "source": [
    "nb_dic = naive_bayes_constructor(features,response,reviews_hex,return_cm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cm_list': [[(0.0, [[0, 6683], [0, 30650]]), (0.050000000000000003, [[848, 5835], [3666, 26984]]), (0.10000000000000001, [[875, 5808], [3803, 26847]]), (0.15000000000000002, [[890, 5793], [3888, 26762]]), (0.20000000000000001, [[918, 5765], [3958, 26692]]), (0.25, [[935, 5748], [4010, 26640]]), (0.30000000000000004, [[943, 5740], [4057, 26593]]), (0.35000000000000003, [[955, 5728], [4096, 26554]]), (0.40000000000000002, [[964, 5719], [4156, 26494]]), (0.45000000000000001, [[970, 5713], [4210, 26440]]), (0.5, [[975, 5708], [4254, 26396]]), (0.55000000000000004, [[984, 5699], [4295, 26355]]), (0.60000000000000009, [[996, 5687], [4326, 26324]]), (0.65000000000000002, [[1007, 5676], [4378, 26272]]), (0.70000000000000007, [[1015, 5668], [4432, 26218]]), (0.75, [[1029, 5654], [4492, 26158]]), (0.80000000000000004, [[1047, 5636], [4566, 26084]]), (0.85000000000000009, [[1067, 5616], [4643, 26007]]), (0.90000000000000002, [[1094, 5589], [4753, 25897]]), (0.95000000000000007, [[1148, 5535], [4966, 25684]])], [(0.0, [[0, 6655], [0, 30811]]), (0.050000000000000003, [[862, 5793], [3880, 26931]]), (0.10000000000000001, [[882, 5773], [3997, 26814]]), (0.15000000000000002, [[894, 5761], [4097, 26714]]), (0.20000000000000001, [[906, 5749], [4147, 26664]]), (0.25, [[913, 5742], [4211, 26600]]), (0.30000000000000004, [[932, 5723], [4274, 26537]]), (0.35000000000000003, [[948, 5707], [4321, 26490]]), (0.40000000000000002, [[959, 5696], [4366, 26445]]), (0.45000000000000001, [[966, 5689], [4413, 26398]]), (0.5, [[977, 5678], [4471, 26340]]), (0.55000000000000004, [[989, 5666], [4513, 26298]]), (0.60000000000000009, [[1000, 5655], [4557, 26254]]), (0.65000000000000002, [[1008, 5647], [4608, 26203]]), (0.70000000000000007, [[1017, 5638], [4662, 26149]]), (0.75, [[1039, 5616], [4714, 26097]]), (0.80000000000000004, [[1052, 5603], [4785, 26026]]), (0.85000000000000009, [[1067, 5588], [4890, 25921]]), (0.90000000000000002, [[1099, 5556], [5015, 25796]]), (0.95000000000000007, [[1145, 5510], [5198, 25613]])], [(0.0, [[0, 6698], [0, 30603]]), (0.050000000000000003, [[924, 5774], [3987, 26616]]), (0.10000000000000001, [[949, 5749], [4100, 26503]]), (0.15000000000000002, [[970, 5728], [4158, 26445]]), (0.20000000000000001, [[986, 5712], [4230, 26373]]), (0.25, [[997, 5701], [4282, 26321]]), (0.30000000000000004, [[1007, 5691], [4333, 26270]]), (0.35000000000000003, [[1011, 5687], [4366, 26237]]), (0.40000000000000002, [[1018, 5680], [4407, 26196]]), (0.45000000000000001, [[1027, 5671], [4435, 26168]]), (0.5, [[1029, 5669], [4476, 26127]]), (0.55000000000000004, [[1040, 5658], [4518, 26085]]), (0.60000000000000009, [[1045, 5653], [4554, 26049]]), (0.65000000000000002, [[1055, 5643], [4590, 26013]]), (0.70000000000000007, [[1066, 5632], [4650, 25953]]), (0.75, [[1079, 5619], [4722, 25881]]), (0.80000000000000004, [[1100, 5598], [4794, 25809]]), (0.85000000000000009, [[1125, 5573], [4868, 25735]]), (0.90000000000000002, [[1152, 5546], [4973, 25630]]), (0.95000000000000007, [[1200, 5498], [5153, 25450]])], [(0.0, [[0, 6663], [0, 30812]]), (0.050000000000000003, [[899, 5764], [3834, 26978]]), (0.10000000000000001, [[922, 5741], [3946, 26866]]), (0.15000000000000002, [[932, 5731], [4010, 26802]]), (0.20000000000000001, [[945, 5718], [4049, 26763]]), (0.25, [[958, 5705], [4112, 26700]]), (0.30000000000000004, [[966, 5697], [4145, 26667]]), (0.35000000000000003, [[974, 5689], [4181, 26631]]), (0.40000000000000002, [[979, 5684], [4203, 26609]]), (0.45000000000000001, [[987, 5676], [4239, 26573]]), (0.5, [[994, 5669], [4275, 26537]]), (0.55000000000000004, [[999, 5664], [4306, 26506]]), (0.60000000000000009, [[1008, 5655], [4347, 26465]]), (0.65000000000000002, [[1016, 5647], [4380, 26432]]), (0.70000000000000007, [[1027, 5636], [4429, 26383]]), (0.75, [[1036, 5627], [4488, 26324]]), (0.80000000000000004, [[1045, 5618], [4544, 26268]]), (0.85000000000000009, [[1062, 5601], [4611, 26201]]), (0.90000000000000002, [[1079, 5584], [4705, 26107]]), (0.95000000000000007, [[1122, 5541], [4868, 25944]])], [(0.0, [[0, 6739], [0, 30994]]), (0.050000000000000003, [[862, 5877], [3714, 27280]]), (0.10000000000000001, [[893, 5846], [3840, 27154]]), (0.15000000000000002, [[918, 5821], [3950, 27044]]), (0.20000000000000001, [[930, 5809], [4030, 26964]]), (0.25, [[947, 5792], [4089, 26905]]), (0.30000000000000004, [[959, 5780], [4141, 26853]]), (0.35000000000000003, [[964, 5775], [4194, 26800]]), (0.40000000000000002, [[975, 5764], [4258, 26736]]), (0.45000000000000001, [[985, 5754], [4300, 26694]]), (0.5, [[996, 5743], [4336, 26658]]), (0.55000000000000004, [[1005, 5734], [4382, 26612]]), (0.60000000000000009, [[1018, 5721], [4431, 26563]]), (0.65000000000000002, [[1026, 5713], [4475, 26519]]), (0.70000000000000007, [[1038, 5701], [4537, 26457]]), (0.75, [[1055, 5684], [4590, 26404]]), (0.80000000000000004, [[1076, 5663], [4678, 26316]]), (0.85000000000000009, [[1099, 5640], [4771, 26223]]), (0.90000000000000002, [[1127, 5612], [4907, 26087]]), (0.95000000000000007, [[1173, 5566], [5122, 25872]])]], 'avg_acc': 0.8214800018858229, 'acc_list': [0.8209894731202957, 0.8223722842043453, 0.8204337685316747, 0.8222014676450967, 0.8214030159277026], 'auc_list': [0.5092217647513998, 0.5041116385858564, 0.5051826726121373, 0.5043818214323993, 0.5089078530849874], 'avg_auc': 0.506361150093356}\n"
     ]
    }
   ],
   "source": [
    "print nb_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = float(df['Sentiment'].value_counts()['positive'])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8206586292908896"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
